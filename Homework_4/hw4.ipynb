{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4 Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4 Fictitious Play"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "payoff_matrix_player_1 = np.array([[1, 2, 3, 3], [3, 4, 2, 4], [1, 2, 5, 2]])\n",
    "payoff_matrix_player_2 = np.array([[5, 2, 4, 1], [0, 1, 5, 2], [3, 6, 2, 3]])\n",
    "payoff_matrix_player_2 = np.transpose(payoff_matrix_player_2)\n",
    "\n",
    "player_1_counts = np.array([1, 1, 1])\n",
    "player_2_counts = np.array([1, 1, 1, 1])\n",
    "\n",
    "player_1_pi_matrix = np.array([player_1_counts[0] / np.sum(player_1_counts), player_1_counts[1] / np.sum(\n",
    "    player_1_counts), player_1_counts[2] / np.sum(player_1_counts)])\n",
    "player_2_pi_matrix = np.array([player_2_counts[0] / np.sum(player_2_counts), player_2_counts[1] / np.sum(\n",
    "    player_2_counts), player_2_counts[2] / np.sum(player_2_counts), player_2_counts[3] / np.sum(player_2_counts)])\n",
    "\n",
    "\n",
    "for i in range(100):\n",
    "    player_1_payoff = np.dot(payoff_matrix_player_1, player_2_pi_matrix)\n",
    "    player_2_payoff = np.dot(payoff_matrix_player_2, player_1_pi_matrix)\n",
    "\n",
    "    player_1_counts[np.argmax(player_1_payoff)] += 1\n",
    "    player_2_counts[np.argmax(player_2_payoff)] += 1\n",
    "    player_1_pi_matrix = np.array([player_1_counts[0] / np.sum(player_1_counts), player_1_counts[1] / np.sum(\n",
    "        player_1_counts), player_1_counts[2] / np.sum(player_1_counts)])\n",
    "    player_2_pi_matrix = np.array([player_2_counts[0] / np.sum(player_2_counts), player_2_counts[1] / np.sum(\n",
    "        player_2_counts), player_2_counts[2] / np.sum(player_2_counts), player_2_counts[3] / np.sum(player_2_counts)])\n",
    "\n",
    "print(\"Player 1 counts: \", player_1_counts)\n",
    "print(\"Player 2 counts: \", player_2_counts)\n",
    "print(\"Player 1 pi matrix: \", player_1_pi_matrix)\n",
    "print(\"Player 2 pi matrix: \", player_2_pi_matrix)\n",
    "\n",
    "\n",
    "# Results 1000000 iterations\n",
    "# Player 1 counts:  [     1 500556 499446]\n",
    "# Player 2 counts:  [     1 600020 399982      1]\n",
    "# Player 1 pi matrix:  [9.99997000e-07 5.00554498e-01 4.99444502e-01]\n",
    "# Player 2 pi matrix:  [9.999960e-07 6.000176e-01 3.999804e-01 9.999960e-07]\n",
    "\n",
    "# Results 100 iterations\n",
    "# Player 1 counts:  [ 1 47 55]\n",
    "# Player 2 counts:  [ 1 64 38  1]\n",
    "# Player 1 pi matrix:  [0.00970874 0.45631068 0.53398058]\n",
    "# Player 2 pi matrix:  [0.00961538 0.61538462 0.36538462 0.00961538]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Warming up . . ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def run_experiemnt(n: int) -> tuple[float, float]:\n",
    "    cos_values = np.ndarray(shape=(n))\n",
    "    x = np.random.normal(0.0, 1.0, n)\n",
    "    cos_2 = lambda x: np.cos(x) * np.cos(x)\n",
    "    cos_values = cos_2(x)\n",
    "    return cos_values.mean(), cos_values.std()\n",
    "\n",
    "n = 1000000\n",
    "mean, std = run_experiemnt(n)\n",
    "print(F\"Mean: {mean}\")\n",
    "print(F\"STD: {std}\")\n",
    "print(F\"[{mean - 1.96*(std/np.sqrt(n))};{mean + 1.96*(std/np.sqrt(n))}]\")\n",
    "\n",
    "margin_of_error = 1.96 * (std / np.sqrt(n))\n",
    "print(f\"Margin of Error: {margin_of_error}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Quantifying the significance of an observed correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(0)\n",
    "\n",
    "# Parameters\n",
    "num_simulations = 1000000  # Number of Monte Carlo simulations\n",
    "observed_corr = 0.3  # Observed correlation value\n",
    "num_experiments = 10  # Number of experiments you have conducted\n",
    "\n",
    "# Function to generate random data and calculate correlation\n",
    "def simulate_correlation(num_experiments):\n",
    "    # Simulate independent data for A and S\n",
    "    A = np.random.rand(num_experiments)\n",
    "    S = np.random.rand(num_experiments)\n",
    "    \n",
    "    # Calculate and return correlation coefficient\n",
    "    return np.corrcoef(A, S)[0, 1]\n",
    "\n",
    "# Running the Monte Carlo simulation\n",
    "extreme_count = 0\n",
    "for _ in range(num_simulations):\n",
    "    corr = simulate_correlation(num_experiments)\n",
    "    if abs(corr) >= observed_corr:\n",
    "        extreme_count += 1\n",
    "\n",
    "# Calculate p-value\n",
    "p_value = extreme_count / num_simulations\n",
    "\n",
    "# Output the result\n",
    "print(f\"Simulated p-value: {p_value}\")\n",
    "\n",
    "# Interpretation\n",
    "if p_value < 0.05:\n",
    "    print(\"The correlation is likely significant.\")\n",
    "else:\n",
    "    print(\"The correlation is not statistically significant.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.4 Kullback-Leibler divergence"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "# Function to compute KL divergence between two normal distributions\n",
    "def kl_divergence(mu1, sigma1, mu2, sigma2, sample_size=1000000):\n",
    "    # Generate samples from the two normal distributions\n",
    "    samples_f = np.random.normal(mu1, sigma1, sample_size)\n",
    "\n",
    "    # Evaluate the PDFs of the normal distributions\n",
    "    pdf_f = norm.pdf(samples_f, mu1, sigma1)\n",
    "    pdf_g = norm.pdf(samples_f, mu2, sigma2)\n",
    "\n",
    "    # Compute the sample-based estimate of the KL divergence\n",
    "    kl_estimate = np.mean(np.log(pdf_f / pdf_g))\n",
    "\n",
    "    return kl_estimate\n",
    "\n",
    "# Parameters of the normal distributions\n",
    "mu1, sigma1 = 1.0, 1.0\n",
    "mu2, sigma2 = 2.0, 3.0\n",
    "\n",
    "# Theoretical result of KL divergence\n",
    "theoretical_kl = 0.5 * ((sigma1**2) / (sigma2**2) + ((mu1 - mu2)**2) / (sigma2**2) - 1 + np.log(sigma2**2 / sigma1**2))\n",
    "\n",
    "# Monte Carlo estimate of KL divergence\n",
    "mc_estimate = kl_divergence(mu1, sigma1, mu2, sigma2)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Theoretical KL Divergence: {theoretical_kl}\")\n",
    "print(f\"Monte Carlo Estimate: {mc_estimate}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
